{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series of Wikipedia Page Revisions\n",
    "\n",
    "**Author**: Eni Mustafaraj  \n",
    "**Date**: Original notebook on Oct 2021. New data collected in Dec 2022. Current version: Mar 2024.\n",
    "\n",
    "**Explanation:** This notebook was part of a course in which students learned to work with the MediaWiki API and used it to get the list of revisions for Wikipedia pages. Having such revisions allow us to investigate how events in the real-world affect the behavior of Wikipedia editors. This notebook has a companion notebook that shows how the data is collected from Wikipedia. It starts off with loading the data received from the API call and it focuses on massaging that data to turn it into a format that can be visualized. \n",
    "\n",
    "The data in each file contains the history of revisions on the Wikipedia pages of four famous female artistis.\n",
    "\n",
    "\n",
    "**Table of Content**\n",
    "\n",
    "1. [Data Exploration](#sec1)\n",
    "2. [Data Massaging](#sec2)\n",
    "3. [Visualizing the time series](#sec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## 1. Data Exploration\n",
    "\n",
    "We will load the data from the JSON files, that are stored in the folder raw_data_2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "folder = \"raw_data_2022\"\n",
    "\n",
    "files = os.listdir(folder) # read content of folder\n",
    "files = [file for file in files if file.endswith('json')] # ensure that we will read only JSON files\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store their content into a dictionary, because so it's easier to access them all together, instead of having several named variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dictionary to store the content of each JSON file\n",
    "rawRevisionsDct = {}\n",
    "\n",
    "for filename in files:\n",
    "    name = filename.split('_')[0]\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    rawRevisionsDct[name] = json.load(open(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what was stored in this dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(rawRevisionsDct.keys())\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now check the values associated with one of the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawRevisionsDct[names[0]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the value for the key 'timestamp' is in a list format, instead as of time or datetime object. This is because when we turn an object into JSON format, some data structures have to be flattened and turned into simpler data structures, such as lists or dicts, because JSON only accepts the simpler data structures (string, list, dict), and not complex types such as datetime.\n",
    "\n",
    "Our goal in the following is to convert the list of the year,month,day,hour, etc. values into a datetime object. We will first excplicitely convert the list into a tuple value, otherwise the function `mktime` below will complain about the passed argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import mktime\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_timestamp(ts):\n",
    "    \"\"\"Convert the timestamp into a datetime object.\n",
    "    \"\"\"\n",
    "    return datetime.fromtimestamp(mktime(tuple(ts))) # mktime expects a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function on one timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = rawRevisionsDct[names[0]][0]['timestamp']\n",
    "convert_timestamp(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the only thing we care about from this data at the moment is the timestamps, we will create a simple dictionary of lists to store the converted timestamps of the revisions for each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dictionary to only store the timestamps\n",
    "timeSeriesDct = {}\n",
    "\n",
    "for name in rawRevisionsDct:\n",
    "    revLst = rawRevisionsDct[name]\n",
    "    timeSeriesDct[name] = [convert_timestamp(rev['timestamp']) for rev in revLst]\n",
    "    \n",
    "    \n",
    "# let's test it\n",
    "for name in timeSeriesDct:\n",
    "    print(name, len(timeSeriesDct[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each list associated with a key has a different number of timestamps. And we can check to make sure that they are datetime objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeriesDct['Alicia Keys'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisions on a page can happen at any time. Often there is only one revision once in a while, and at other times there are dozen of revisions in a single date. Ideally, we want the revisions to be shown at more regular intervals, such as the total revisions in a month.\n",
    "\n",
    "We can do that if we work with timeseries objects. But, given that we have multiple artists, it will be good to create a dataframe with two additional columns: timestamp, artist, count. We are going to set the count at 1, since each revision is one event on its own. \n",
    "\n",
    "Let's try it out for one artist and then we can package the code into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "alicia = timeSeriesDct['Alicia Keys']\n",
    "\n",
    "triplets = [(alicia[i], 1, 'Alicia Keys') for i in range(len(alicia))]\n",
    "df = pd.DataFrame(triplets, columns=['Timestamp', 'Count', 'Artist'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can turn this into a timeseries by setting the Timestamp column to be the index of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Timestamp', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can use the method `resample` to find the counts by month (using the symbol 'ME' for month-end):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample('ME')['Count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few things to notice here:\n",
    "- the count values have been summed, \n",
    "- timestamps have been ordered from the earliest to the most recent\n",
    "\n",
    "It also looks like months that were not in the data were included with the count 0. Let's make sure that this is the case, by asking for 12 months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample('ME')['Count'].sum()[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows an entire year from June 2002 to May 2003, no missing months, even though there were no timestamps for several months. This is quite good for our purposes, because we don't have to worry about missing indices within the datarange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one issue with the result, it's shown as a series, while we would like to operate with a dataframe. But we can easily fix it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Artist').resample('ME')['Count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a perfect tidy table. Each row is an observation of how many revisions were performed during a particular month on one's artist Wikipedia page. Now that we now how to do this for one artist, we can go and do it for all artists and then further massage the data to be in the shape we want for the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## 2. Data Massaging\n",
    "\n",
    "Our ultimate goal is to produce a visualization similar to this one from Plotly's website tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.stocks(indexed=True)-1\n",
    "fig = px.area(df, facet_col=\"company\", facet_col_wrap=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finding such visualizations is always good to see what the dataframe looks like, so that we know what we need to aim for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we notice here is that this table is not a tidy table, instead is a pivot table each column is the name of a company. \n",
    "Eventually, we also will need to transform our dataframe to this format, from a tidy long table to a wide table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to create each dataframe**\n",
    "\n",
    "We will take the code we wrote before and package it into a function, since we have multiple artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def createDF(timestamps, name):\n",
    "    \"\"\"Create a dataframe from the timestamps.\n",
    "    \"\"\" \n",
    "    triplets = [(timestamps[i], 1, name) for i in range(len(timestamps))]\n",
    "    df = pd.DataFrame(triplets, \n",
    "                      columns=['Timestamp', 'Count', 'Artist'])\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "    dfCounts = df.groupby('Artist').resample('ME')['Count'].sum().reset_index()\n",
    "    return dfCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function with each artist and its associated timestamps list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for artist in timeSeriesDct:\n",
    "    dataframes.append(createDF(timeSeriesDct[artist], artist))\n",
    "\n",
    "for df in dataframes:\n",
    "    print(df.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can notive from the printed dataframes is that they start at different years, which is to be expected since these artists are of different ages. We will sort them from the earliest to the latest, before we combine them together, so that they are ordered when we create the plot. We can find the earliest timestamp with this line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[0]['Timestamp'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use this value, as our key for sorting by time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.sort(key=lambda item: item['Timestamp'].min())\n",
    "\n",
    "# Check that the dataframes were sorted\n",
    "for df in dataframes:\n",
    "    print(df.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will simply concatenate all of them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = pd.concat(dataframes)\n",
    "dfMerged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that this dataframe is big, as a result of the concatenation. Let's see how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the concatenation has kept the original index values, so we need to reset the index and make sure to drop the old one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.reset_index(drop=True, inplace=True)\n",
    "dfMerged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our table is a nice tidy long table, we can easily turn it into a pivot table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = dfMerged.pivot(index='Timestamp', \n",
    "                         columns='Artist', \n",
    "                         values='Count').fillna(0)\n",
    "finalDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, but it looks like the transformation has changed the order of columns to be alphabetical. Meanwhile, we want to start with the oldest timeseries, as we had them in dfMerged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the order of the columns\n",
    "dfMerged['Artist'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the method `reindex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = finalDF.reindex(columns=list(dfMerged['Artist'].unique()))\n",
    "finalDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the order we want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3'></a>\n",
    "## 3. Visualizing the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at the dataframe of the example we are trying to emulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.stocks(indexed=True)-1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like our dataframe looks quite similar to this example, so we can try to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(finalDF, facet_col=\"Artist\", facet_col_wrap=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can show them in one single column, so it's easier to compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(finalDF, facet_col=\"Artist\", facet_col_wrap=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to decorate this graph to provide titles for the axes, the whole plot, increase the height, reduce the width, set the subplot y axis labels to an empty string (since they are repeated),  etc. That makes sense to do if we end up using the graph for communication purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
