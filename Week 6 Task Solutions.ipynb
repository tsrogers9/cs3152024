{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644e74d1-7750-4f87-9758-b2a4d369ddd9",
   "metadata": {},
   "source": [
    "# Week 6 Tasks: NYT API Data and Cosine Similarity for Text \n",
    "\n",
    "These tasks were discussed during week 6 and you had to work on them with your group.  \n",
    "Below are the solutions and additional tasks that will be helpful for your project.\n",
    "\n",
    "**Table of Content**\n",
    "* [Part 1: Working with the NYT API](#sec1)\n",
    "* [Part 2: Cosine Similarity for Text](#sec2)\n",
    "* [Part 3: Similarity of Spring and Summer sentences](#sec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47288b9e-1d91-4df6-8c98-01d8082c6172",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## Part 1: Working with the NYT API \n",
    "\n",
    "We have the following goals:\n",
    "\n",
    "1. Use the API to get all articles from a month\n",
    "2. Verify the number of articles\n",
    "3. Find the distribution of articles by section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5235f-e011-42c5-afcd-4678c615fcf1",
   "metadata": {},
   "source": [
    "### Important: replace the string below with your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eded646-a519-4488-9efb-dd5e68c1d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "myAPIkey = \"ADD YOUR OWN API KEY HERE!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d637cf-7eac-45b1-b6c9-a3c28dd06813",
   "metadata": {},
   "source": [
    "We will write a function that given a date (month and year) will talk to the NYT API and get the articles for that time period. We will store the results in a JSON file to process when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e6acc-2c29-43ec-8f9a-99de35b5eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "def getNYTArticles(year, month, apiKey):\n",
    "    \"\"\"Function that sends a request to the NYT API for all articles in a month\n",
    "    and then stores the results in a JSON file.\n",
    "    \"\"\"\n",
    "    # create URL\n",
    "    URL = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={apiKey}\"\n",
    "\n",
    "    # send the request to get the data\n",
    "    data = requests.get(URL)\n",
    "    if data.status_code == 200:\n",
    "        print(\"Successfully got the data.\")\n",
    "\n",
    "    dataJson = data.json() # get response as JSON\n",
    "\n",
    "    with open(f\"NYT_{year}-{month}.json\", 'w') as fout:\n",
    "        json.dump(dataJson, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5a98c-0641-4336-8d34-35c626579eab",
   "metadata": {},
   "source": [
    "Let's test the function for the months of February 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9ff83-df33-4037-ad86-b029bd53116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "getNYTArticles(2024, 2, myAPIkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1d927-2713-4a74-9d2d-05cfde14e136",
   "metadata": {},
   "source": [
    "## Explore the NYT Data\n",
    "\n",
    "Now that we have the data, we will look into how to retrieve things like article title, section, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d2c5c4-696d-4518-a513-443d3db5fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NYT_2024-2.json\") as fin:\n",
    "    articles = json.load(fin)\n",
    "\n",
    "print(type(articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe47492-d11a-45d4-b1a9-3ebf1aeed9cf",
   "metadata": {},
   "source": [
    "We can check the keys of this dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c6639-9d09-47e0-8299-b1733379e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414a10a-b15a-44b4-805f-70877b0f6c3f",
   "metadata": {},
   "source": [
    "Then we check what values are stored under each key, without printing the values, but checking for their type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c542d6-248d-40aa-a580-443f4b68aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in articles:\n",
    "    print(key, type(articles[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b5d15-0bac-47c0-8acd-57a4e3d0f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['copyright']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7ac7a-003a-4413-ad3d-aaaa4f893c24",
   "metadata": {},
   "source": [
    "Let's look at the keys for 'response':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f21c0e-0fd0-45b1-b80b-d82cd6672472",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['response'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d43299-30db-404b-a80d-1ed2c75fc453",
   "metadata": {},
   "source": [
    "One more time, we look what kind of information is stored under each of these keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affb171-a949-4507-928d-bde3c03ca065",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in articles['response']:\n",
    "    print(key, type(articles['response'][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13648859-3869-4274-98ca-4ed39e8ebc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is under the \"meta\" key?\n",
    "\n",
    "articles['response']['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac6aee-0f8a-4ac2-a51d-eb57cad8664d",
   "metadata": {},
   "source": [
    "So, this shows how many articles are in the data. We can verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f30f73-eb9e-4865-801d-54fb7452eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles['response']['docs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b437bb-dc0d-4162-8369-ce547030d873",
   "metadata": {},
   "source": [
    "It's the same number, which is a good thing. Now let's look at what one of the articles (or docs) looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e6715-f6ec-4d9a-bdd6-23cb86fee3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['response']['docs'][0] # using indexing, because we know that the data is stored in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50978e8-b3aa-41c5-b549-4b4f99941214",
   "metadata": {},
   "source": [
    "We can see tha an article is a somewhat nested data structure, it's a dictionary, but many of the keys point to list of other dictionaries. Let's look at the top fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0c987-974d-4e76-aa5e-afb05fa33ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneArticle = articles['response']['docs'][0]\n",
    "for key in oneArticle:\n",
    "    print(key, type(oneArticle[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc22ee-0748-4850-bc23-272d0dbc6340",
   "metadata": {},
   "source": [
    "### Find the distribution of articles by section\n",
    "\n",
    "As we saw above, every article has a section name, so we can easily collect all those names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0f050-8a06-45a6-b33d-b6b2a485abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [article['section_name'] for article in articles['response']['docs']]\n",
    "\n",
    "# Let's look up a few of them\n",
    "sections[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890db0b-3c4f-46a1-8338-b31a4cf4acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "distDct = Counter(sections) # count the occurrences of each section name\n",
    "\n",
    "distDct.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383daa6-b200-45dd-a49f-fdf15f040518",
   "metadata": {},
   "source": [
    "## Tasks for you:\n",
    "\n",
    "1. Write a Python function that takes a date, for example, \"2024-02-12\", and returns the list of articles for that day.\n",
    "2. Write some code that explores whether the fields \"abstract\" and \"snippet\" are always the same or they differ. Which one has more information?\n",
    "3. Write a function that given one article (in its nested structure), creates a flat dictionary with keys that are relevant for analysis: either the abstract or snippet (see point 2); lead paragraph; headline; keywords concatenated via semicolon; pub_date; document_type; section_name; and type_of_material\n",
    "4. Write another function that calls the function from point 3 on every article, to create a list of article dictionaries, and convert this list into a dataframe and then store it as a CSV file with the date-month in the title (this is important for point 5 below).\n",
    "5. Once you have done all of these in the notebook, create a Python script that can be called with a date (from a TikTok video). First, the script looks whether a CSV with cleaned articles is in our folder. If not, calls first the API function to get the articles and then the function that converts them into a CSV. Then, it loads the CSV into a datafram and it uses filtering to get the articles for the desired date. These articles will be used for the Semantic Similarity portion of the TikTok Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2581b-de88-4e84-8a1c-cb0287025661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a68c4-e845-4fae-b891-43d64ebb1acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "061baf0d-6c54-457b-b3d7-aecd0fd29b10",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## Part 2: Cosine Similarity for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ba378-a8b9-44c2-806c-d46672d67d12",
   "metadata": {},
   "source": [
    "We will start with the example that was in the slides. There, we initially used the Jaccard similarity to rank sentences most similar to a query, and when that didn't work as expected, we looked at the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02ccfc-4467-4bc5-9361-6e934c24c4dc",
   "metadata": {},
   "source": [
    "### Use Jaccard similarity for a query phrase and a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2df6d-775c-4c58-b3d4-d72ae5ee94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"red dress\"\n",
    "\n",
    "sentences = [\n",
    "\"she wore a dress and red earrings\",\n",
    "\"the dress has a red wine stain\",\n",
    "\"tomorrow I will wear my new red dress\",\n",
    "\"the red dress in the photo resembles the red dress she is wearing\",\n",
    "\"short dress\",\n",
    "\"red lipstick\"\n",
    "]\n",
    "\n",
    "def jaccard(text1, text2):\n",
    "    \"\"\"Implement Jaccard similarity. Assumes there is no punctuation in text.\"\"\"\n",
    "    sw1 = set(text1.lower().split()) # turn into a set of words\n",
    "    sw2 = set(text2.lower().split())\n",
    "    sim = len(sw1.intersection(sw2)) / len(sw1.union(sw2))\n",
    "    return round(sim, 4) # round to 4 digits after the comma\n",
    "\n",
    "def applyJaccard(query, sentences):\n",
    "    \"\"\"Appl the Jaccard similarity between query and each sentence\"\"\"\n",
    "    results = []\n",
    "    for sent in sentences:\n",
    "        jac = jaccard(query, sent)\n",
    "        results.append((jac, sent))\n",
    "    \n",
    "        # Sort in descending order\n",
    "        results.sort(reverse=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "# call the function\n",
    "\n",
    "applyJaccard(q, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a902535-3e2f-40cb-b1e1-83f12d9cfbdd",
   "metadata": {},
   "source": [
    "As we discussed in class, the Jaccard similarity is not doing well with our data (showing as similar text that, thus, we will try the cosine similarity. However, in order to apply the cosine similarity, we need some other steps:\n",
    "\n",
    "1. Create the vocabulary of words that will serve as the dimensions of our vector space\n",
    "2. Represent each document as a vector in the vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b7baa-d3e9-4ab5-936b-d157ceb4ecaa",
   "metadata": {},
   "source": [
    "### Create Vocabulary\n",
    "\n",
    "While our sentences in the example don't have punctuation, most of the time text will have it, thus, we need to be prepared to remove it. This will be necesary in order to avoid a word show multiple times, with and without punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eada87-b484-4ff6-86ae-8e3da3b44f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"that, that is the thing I want: dancing by the river! ah, the river, I have missed it so much!\"\n",
    "phrase.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10a224-8a04-4cf6-902f-5be5bc39acbc",
   "metadata": {},
   "source": [
    "Notice how we have both \"that!\" and \"that\", and also \"river,\" and \"river!\". This is why we will remove punctuation. Luckily, Python has a library that lists all punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a24b4-dbed-47a5-aef3-6932ae997af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721a72c-0d0a-4b72-9dfc-da57935f5cd4",
   "metadata": {},
   "source": [
    "One way to go about it is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbb783-deea-4385-8133-3ba596115a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(char for char in phrase if char not in string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3885419-d1b4-470f-b877-7b352eb43522",
   "metadata": {},
   "source": [
    "Notice how all the punctuation is gone. Now that we know how to do this, we can write our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b23d86-8bd4-48a6-96b8-5acea2294f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulary(textchunk):\n",
    "    \"\"\"Given some text, create the vocabulary of unique words.\"\"\"\n",
    "    textchunk = textchunk.lower()\n",
    "    cleantext = \"\".join(char for char in textchunk if char not in string.punctuation)\n",
    "    words = set(cleantext.split())\n",
    "    voc = sorted(words)\n",
    "\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec90fd-b1d9-41b5-bf1d-b0ff75d8576c",
   "metadata": {},
   "source": [
    "Let's test it with our sentences. Since they are a list, we turn them into a string first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8530bd-7e6c-423b-a6c1-9d8a5a3d3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "getVocabulary(\" \".join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570aa541-20e6-4649-a072-e7747c8c0e7c",
   "metadata": {},
   "source": [
    "It looks good, no word is repeated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b4d6b-ed75-46dd-8eb7-cdc086929acb",
   "metadata": {},
   "source": [
    "### Vector representation\n",
    "\n",
    "Now that we have a vocabulary, we can easily convert every sentence into a vector of numbers. Remember, all the vectors will have the same length. They will have 0 for a dimension (word) that they don't have, and the count of word for a dimension they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df263f81-89fe-43e0-b8c2-c3a7389cbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vector(sentence, voc):\n",
    "    \"\"\"Given a sentence and the vocabulary for the problem,\n",
    "    turn every sentence into a vector.\n",
    "    \"\"\"\n",
    "    cleantext = \"\".join(char for char in sentence if char not in string.punctuation)\n",
    "    words = cleantext.lower().split()\n",
    "    vector = [words.count(w) for w in voc]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373e862-7388-441f-be8c-df4858a5049d",
   "metadata": {},
   "source": [
    "Let's try it with one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41a829-15bb-4cfb-87b6-71fe59f1eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = getVocabulary(\" \".join(sentences))\n",
    "text2vector(sentences[0], voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3160b6-9859-4232-9633-8c7c9d1554df",
   "metadata": {},
   "source": [
    "Let's verify that this is done right by checking what sentence was turned into a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0bd5c3-d39d-45df-b299-d68985f95e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283598ad-4b39-4971-8678-07e9e58a5fe8",
   "metadata": {},
   "source": [
    "Let's combine the vocabulary and the vector to see the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07681d03-9145-4d0d-bc62-35d8e7d08091",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(voc, text2vector(sentences[0], voc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044674c-702e-41cd-acf7-a256ad70319b",
   "metadata": {},
   "source": [
    "Notice how each word in our sentence has a 1 next to it and all the other words have a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cbe7f-5532-4400-9072-e5be860c9c29",
   "metadata": {},
   "source": [
    "We will now convert all the sentences to vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f4537-e117-4a85-9abc-9f7d5a0f232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2vec = [text2vector(sent, voc) for sent in sentences]\n",
    "sent2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d6ada-dfdd-46c2-819c-78eeef345a0c",
   "metadata": {},
   "source": [
    "We represent this in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80266fcd-74f1-425c-b9f7-7d5cf5e2fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(sent2vec, \n",
    "                  columns=voc,\n",
    "                  index=[f\"doc_{i+1}\" for i in range(len(sentences))])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb0b24-529d-4729-9536-07133eed7954",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "We discussed the implementation of cosine similarity in class. Below is the function that implements it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56ea1c-ad57-4932-897f-853683b8dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "def cosineSimilarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    V1 = np.array(vec1)\n",
    "    V2 = np.array(vec2)\n",
    "    cosine = np.dot(V1, V2)/(norm(V1)*norm(V2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180583c-772e-417d-9bb3-5a757cd4b02a",
   "metadata": {},
   "source": [
    "Now that we have the cosine similarity function, we will write a function that given a query and a list of sentences, calculates the similarity score for each pair (query, sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84fcec-d7b6-4778-b325-f71186be5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankDocuments(query, sentences):\n",
    "    \"\"\"Given a query and some sentences, rank the sentences for \n",
    "    which are the most similar to the query.\n",
    "    \"\"\"\n",
    "    # Step 1: create vocabulary\n",
    "    voc = getVocabulary(\" \".join(sentences))\n",
    "\n",
    "    # Step 2: generate vector for query\n",
    "    queryVec = text2vector(query, voc)\n",
    "\n",
    "    # Step 3: generate vector for sentences and calculate cosine similarity at once\n",
    "    similarities = []\n",
    "    for sent in sentences:\n",
    "        sentVec = text2vector(sent, voc)\n",
    "        sim = cosineSimilarity(queryVec, sentVec)\n",
    "        similarities.append((round(sim, 4), sent)) # keep track of sentences\n",
    "\n",
    "    similarities.sort(reverse=True) # most similar sentence at the top\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34727669-66b5-457a-bd42-179a69b7e0dd",
   "metadata": {},
   "source": [
    "Now we can call the function for our query \"red dress\" and the list of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2c623-8e46-41c2-a5c8-44f16ef214a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankDocuments(\"red dress\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f57d06-5e24-499b-ba9d-71206812ee93",
   "metadata": {},
   "source": [
    "**Note:** These values are slightly different from the ones in the slides. There was a bug with the word \"I\", which was not lowercased in the sentences, so it didn't count in the vector. The bug has been fixed in this version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31052f-a095-4a3b-963d-93ea3d8aa447",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## Part 3: Similarity of Spring and Summer sentences\n",
    "\n",
    "You were given the following sentences in the slides of Day 10. These were created by GenAI to capture the spirit of \"spring\" and \"summer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac7add-0cab-4e15-8c8c-670a22bd24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "springSentences = [\n",
    "\"As spring unfolds, the warmth of the season encourages the first blossoms to open, signaling longer days ahead.\",\n",
    "\"Spring brings not only blooming flowers but also the anticipation of sunny days and outdoor activities.\",\n",
    "\"With the arrival of spring, people begin planning their summer vacations, eager to enjoy the seasonal warmth.\",\n",
    "\"The mild spring weather marks the transition from the cold winter to the inviting warmth of summer.\",\n",
    "\"During spring, families often start spending more time outdoors, enjoying the season's pleasant temperatures and the promise of summer fun.\"\n",
    "]\n",
    "\n",
    "summerSentences = [\n",
    "\"Summer continues the season's trend of growth and warmth, with gardens full of life and days filled with sunlight.\",\n",
    "\"The summer season is synonymous with outdoor adventures and enjoying the extended daylight hours that began in spring.\",\n",
    "\"As summer arrives, the warm weather invites a continuation of the outdoor activities that people began enjoying in spring.\",\n",
    "\"The transition into summer brings even warmer temperatures, allowing for beach visits and swimming, much awaited since the spring.\",\n",
    "\"Summer vacations are often planned as the days grow longer, a pattern that starts in the spring, culminating in peak summer leisure.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d7cfd-7d88-4ae0-a4d8-fd57d7abf98f",
   "metadata": {},
   "source": [
    "**Our Goal:**\n",
    "\n",
    "We want to generate a heatmap of the similarity scores between all sentences to one another to find out how similar they are. To achieve this goal, we need to break down the task:\n",
    "\n",
    "1. We need to create first the vocabulary of all terms (or the dimensions of our vector space).\n",
    "2. We will turn every sentence into a vector.\n",
    "3. We will compare every sentence to every other sentence through the cosine similartiy to create the similarity matrix.\n",
    "4. We will draw the heatmap with seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d4566-ff9e-440f-8270-28266576f1d4",
   "metadata": {},
   "source": [
    "### Create Vocabulary\n",
    "\n",
    "We will call the function `getVocabulary` that we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76cc83-44a6-483a-8b62-504aa457b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "allSentences = \" \".join(springSentences) + \" \" + \" \".join(summerSentences)\n",
    "voc = getVocabulary(allSentences)\n",
    "print(f\"Vocabulary has {len(voc)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e8c8e-3ba6-4186-888c-419c40f4371d",
   "metadata": {},
   "source": [
    "### Convert sentences to vectors\n",
    "\n",
    "We will call the function `text2vector` on every sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cb611-dbc2-4758-949d-8106223faa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentVectors = [text2vector(sent, voc) for sent in springSentences+summerSentences]\n",
    "print(len(sentVectors), len(sentVectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c7b5a-af95-4c18-8055-2595ad5c325c",
   "metadata": {},
   "source": [
    "This means that we created 10 vectors, each with a length of 102 dimensions.  \n",
    "Let's check our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf70219-42ae-470d-a1ee-ed77b5f6df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneSent = springSentences[0]\n",
    "oneSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588ad7d-9c4f-4fb5-8c5b-92d9701e3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(zip(text2vector(oneSent, voc), voc))\n",
    "nonZero = [pair for pair in pairs if pair[0] != 0]\n",
    "nonZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0ed94-87d4-4709-ba59-9554e5ff6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Words in sentence: {len(oneSent.split())}; nonzero terms in vector: {len(nonZero)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0a4c2-acfb-40d6-b15e-dda74d2f5f12",
   "metadata": {},
   "source": [
    "This looks good. There are 16 unique words, and the word \"the\" is repeated two more times, that explains the numbers 16 and 18. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c5533-86e8-4829-9de5-e3e8ac0d8cd0",
   "metadata": {},
   "source": [
    "### Calculating the similarity matrix\n",
    "\n",
    "We will calculate the cosine similarity for every pair of sentences. This makes sense because we only have 10 sentences, if we had way more, we will try to be more efficient and not repeat the calculations (since we know that the matrix is symmetrical). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b9b81-d5b1-43f2-b029-1b15a78014e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simMatrix = []\n",
    "for vec1 in sentVectors:\n",
    "    simRow = []\n",
    "    for vec2 in sentVectors:\n",
    "        simRow.append(cosineSimilarity(vec1, vec2))\n",
    "    simMatrix.append(simRow)\n",
    "\n",
    "print(simMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee2c37-ac61-41de-be5c-1c4d0ed65905",
   "metadata": {},
   "source": [
    "### Generate the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15937a9a-5ed7-4f45-b2a9-8fa4d9b15f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drawHeatmap(sentLabels, simMtrx, plotTitle):\n",
    "    \"\"\"Draws a heatmap for the similarity matrix.\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=0.9)\n",
    "    g = sns.heatmap(\n",
    "          simMtrx, # similarity matrix with the cosine sim values\n",
    "          xticklabels=sentLabels,\n",
    "          yticklabels=sentLabels,\n",
    "          vmin=0,\n",
    "          vmax=1,\n",
    "          cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(sentLabels, rotation=90)\n",
    "    g.set_title(plotTitle, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0d895-0cbc-46e0-abc4-039dac2e69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSent = [sent[:25] for sent in springSentences+summerSentences]\n",
    "drawHeatmap(shortSent, simMatrix, \"Cosine similarity matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb27fe5-0ad2-4e5d-b3ea-d50ae4d1fccb",
   "metadata": {},
   "source": [
    "### Short Exploration\n",
    "\n",
    "Let's look at the similarity matrix in a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a402d1-8fd8-439c-85b5-2ec2524cb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"s{i+1}\" for i in range(10)]\n",
    "df = pd.DataFrame(simMatrix, columns=labels, index=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db3f119-4464-43e2-ac5f-351e6526db01",
   "metadata": {},
   "source": [
    "I will write some code to compare sentences that have a high similarity score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081a313-7a0b-4504-9077-cc8af1d2d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWords(sent):\n",
    "    \"\"\"Get the words of a sentence after lowercasing and removing punctuation.\"\"\"\n",
    "    cleantext = \"\".join(char for char in sent.lower() if char not in string.punctuation)\n",
    "    cleanWords = cleantext.split()\n",
    "    return cleanWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5258d-495a-4ba3-b498-65b080bcf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareSentences(sent1, sent2):\n",
    "    \"\"\"Compare the content of two sentences.\"\"\"\n",
    "    words1 = getWords(sent1)\n",
    "    words2 = getWords(sent2)\n",
    "    commonWords = sorted([w for w in words1 if w in words2])\n",
    "    print(\"COMPARISON RESULTS\")\n",
    "    print(\"Sent1: \", sent1)\n",
    "    print(\"Sent2: \", sent2)\n",
    "    print(f\"Lengths of sentences: {len(words1)} and {len(words2)}. Words in common: {len(commonWords)}\")\n",
    "    print(\"Common words:\", commonWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021a92a-4bb4-4fc8-8689-4b13e9f31307",
   "metadata": {},
   "source": [
    "Let's check s1 and s4, in the group os Spring sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31164c1-f33b-4be3-a43b-ec5eb5c2bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareSentences(springSentences[0], springSentences[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fab4a1-d4f6-4572-bc2d-23814324f8c1",
   "metadata": {},
   "source": [
    "What about the sentences s7 and s8, in the group of Summer sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7e464-6db4-4e99-9b17-77b911ffb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareSentences(summerSentences[1], summerSentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6a16c-48d8-48ab-bfd2-eeadbaf356ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
