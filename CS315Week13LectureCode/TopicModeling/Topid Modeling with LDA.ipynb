{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99d9730-5978-4399-b192-6cfe73bd78a8",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA\n",
    "\n",
    "This tutorial shows how to perform LDA topic modeling using the `sklearn`. It uses different functions to explore the topics and the documents. It is using a small dataset from the NYT articles to keep the interpretation manageable. \n",
    "\n",
    "There are **a few scattered activities for you** in the notebook.\n",
    "\n",
    "\n",
    "**Table of Content**\n",
    "\n",
    "1. [Load the data](#sec1)  \n",
    "2. [Convert to document-term matrix](#sec2)  \n",
    "3. [Fit the LDA model and explore it](#sec3)\n",
    "4. [Finding the most optimal number of topics with GridSearch](#sec4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6bd4b-cf18-48eb-978e-b4a1933cc4ef",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## 1. Load the data\n",
    "\n",
    "I used the NYT API to get all articles from March 2024. Then, I combined together the fields \"snippet\" and \"lead_paragraph\" to create a longer document for each article. Then, I chose the articles for the section_name: food, realestate, and science. I saved the documents only into a json file. \n",
    "\n",
    "Below there is a function that will read a JSON file and turn it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a2fcd-bf16-4e30-bf5a-2c6657f74135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def jsonToDF(name):\n",
    "    \"\"\"Read a list of sentences from the JSON file, store them in a dataframe\"\"\"\n",
    "    \n",
    "    with open(f\"{name}.json\") as fin:\n",
    "        textList = json.load(fin)\n",
    "\n",
    "    # create a name for each document, based on its category\n",
    "    indexNames = [f\"{name}_{i+1}\" for i in range(len(textList))]\n",
    "\n",
    "    # create the dataframe, it will have one column and one index\n",
    "    df = pd.DataFrame(data=textList, index=indexNames)\n",
    "    df.columns = ['document']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa1c82-168e-4c85-81a9-8d8aee69189e",
   "metadata": {},
   "source": [
    "First, let's read the content of all three files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b054e82-8fb4-48d8-8097-58901204094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = jsonToDF(\"food\")\n",
    "realestate = jsonToDF(\"realestate\")\n",
    "science = jsonToDF(\"science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ba486-53d4-42ca-a9d6-b8d83421e6b5",
   "metadata": {},
   "source": [
    "Check one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e94b7-af45-4b55-9688-b72f0b23df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85289d1-577b-4d9a-85f6-db78954b3a73",
   "metadata": {},
   "source": [
    "Check the shape of each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3120885-38f3-4247-ae18-6cdee1f8621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"food:\", food.shape)\n",
    "print(\"realestate:\", realestate.shape)\n",
    "print(\"science:\", science.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731de53-159f-4efb-90ef-0ea27a34c22e",
   "metadata": {},
   "source": [
    "Let's concatenate all of them in a single dataframe for the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832bd85-1daa-4e32-b1c2-fff04095068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs = pd.concat([food, realestate, science])\n",
    "allDocs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d4de4-91bf-4f62-b496-b24f9f176e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4079738-7315-4852-b1d0-5d933048e54f",
   "metadata": {},
   "source": [
    "Make the column wide enough to show all text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aaaef3-cb3c-4ff2-a8a7-5194215f3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac1164-c4df-4036-abdf-429616b8c2f6",
   "metadata": {},
   "source": [
    "Look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532f308-7688-494d-95cc-e64137c4ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8a22b-5265-4fb5-b49e-b22ae8f82eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e687f-0552-4aea-a9ac-9a28de5d978a",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## 2. Convert to document-term matrix\n",
    "\n",
    "We will apply the CountVectorizer to convert our corpus into a document-term matrix. Empirical evidence has shown that simply counting words is more meaningful for performing LDA on documents. (It is possible to use the Tf-idf vectorizer too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603ec70-34fe-4eda-8f4e-c75e891197b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4161269-702a-4006-9c43-d455bdece2fc",
   "metadata": {},
   "source": [
    "This process has always two steps: \n",
    "\n",
    "1. initialize the vectorizer constructor\n",
    "2. apply `fit_transform` to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a120ec0-4afc-4456-9e41-801cb7d0ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b', # we want only words that contain letters and are 3 or more characters long\n",
    ")\n",
    "\n",
    "# Transform our data into the document-term matrix\n",
    "dtm = vectorizer.fit_transform(allDocs['document'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c49a6-0c86-4c3a-88fc-60416743329e",
   "metadata": {},
   "source": [
    "### Exploring the features   \n",
    "Let's look at the features of the \"model\", that is, the columns of our document-term matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e9415-5d67-428e-a9f3-3a7cee7b453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd401a9-0ea4-408f-a59d-6fa33f5803f6",
   "metadata": {},
   "source": [
    "It's an array, let's look at its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ea558-6a87-44e1-bd1b-f544df51fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaeb888-ec28-4434-b1e2-f204a89c628e",
   "metadata": {},
   "source": [
    "Let's look at a larger chunk of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394019cf-6cf7-4bf0-b506-30b0354b06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names[300:350]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8f6e5-cc38-44f4-8a52-07c458be436d",
   "metadata": {},
   "source": [
    "It's clear that these are all cleaned words, three or more characters long, which have not been stemmed. That is, we have both \"bean\" and \"beans\" as two separate features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441c6a9-b806-46dc-8d19-003138f74e1a",
   "metadata": {},
   "source": [
    "### Understanding the document-term matrix\n",
    "\n",
    "Let's look at a single row of the matrix, the first row, which corresponds to the first document from the NYT articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6860bb-fe49-4aec-be62-17f45d0b8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = dtm[0]\n",
    "doc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b510de6-3055-489a-b391-d06cbcbfafe6",
   "metadata": {},
   "source": [
    "It says that it has 4504 colums, but there are only 32 stored elements (terms that are non-zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483867c7-fdbb-47a8-bc01-e638b36026ea",
   "metadata": {},
   "source": [
    "We can use some Python code to find the words and their counts for this document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15978f-db56-4861-9c42-bb1d7b107fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = 0\n",
    "doc_vec = dtm.getrow(row_index).toarray()\n",
    "\n",
    "non_zero_indices = doc_vec.nonzero()[1]\n",
    "dtm_scores = doc_vec[0, non_zero_indices] # goes and retrieves the values corresponding to the non_zero_indices\n",
    "words = [feature_names[i] for i in non_zero_indices]\n",
    "\n",
    "for word, score in zip(words, dtm_scores):\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ff9ed-95bf-4b9e-8548-bb834a2b1de6",
   "metadata": {},
   "source": [
    "We can look at non_zero_indices to check what that variable stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20535fab-52e4-4269-9381-c62f2fae8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765ac9d-fc51-42b3-baec-0f7ebb65ca9f",
   "metadata": {},
   "source": [
    "These values correspond to the column indices of each of the terms (words) in the matrix. A word like \"year\" has a high index, since is toward the end of the matrix, where terms are ordered alphabetically. \n",
    "\n",
    "Now that we know the indices of these words, we can use them to find how often each words occurrs in the entire matrix.\n",
    "\n",
    "We will check the word \"caramelized\", which has the index 599."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fcf0d-bbfe-4760-a952-fd9e2f4d5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.getcol(599).toarray().T # get the column, turn it into an array format, then transpose it to be a row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06004ee-0ad3-4285-8133-adfbf4d8ab8e",
   "metadata": {},
   "source": [
    "It's obvious that the word doesn't show up often, I see only 3 values of 1. Let's check for the word \"vegetables\", index = 4282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a156328-75b8-436c-91b9-5db2411f7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.getcol(4282).toarray().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4c44f-01da-41a8-aba4-2b121f85a5aa",
   "metadata": {},
   "source": [
    "Even this word doesn't show in more than 3 documents in total. Meanwhile, let's see a word like \"year\", index = 4480:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170843d-0df9-49e0-b941-34ffa9659ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.getcol(4480).toarray().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432d6ba-2f86-4d06-9b9e-a1ba793774ef",
   "metadata": {},
   "source": [
    "This seems to occur a bit more often, we can find in how many documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935a083-f208-433a-bd25-5d371e105eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(dtm.getcol(4480).toarray().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3078b-a018-457c-8eab-6a0107a1cf42",
   "metadata": {},
   "source": [
    "### **Task for you:** find the top 5 words from this document (meaning, they show in most articles).\n",
    "\n",
    "Use the variable names that have been seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a8bdb-96dc-4cb7-af3b-170f6d29cef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cabef82-eeb1-48a6-af28-aa7f576609e2",
   "metadata": {},
   "source": [
    "**Reflection questions** \n",
    "\n",
    "1. From these top words would you be able to infer that this document is about cooking/food? \n",
    "\n",
    "2. If these words were part of a **topic**, what would you name that topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf11f7-ec50-44ff-ad6a-553fb67e80db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7574965-face-42cd-a7e7-4b91cdb9ee5f",
   "metadata": {},
   "source": [
    "### Going back to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c44efe-ee5f-40f8-aa8d-988ab464ceec",
   "metadata": {},
   "source": [
    "We can create a function that takes the representation of each document as a row of numbers in the matrix and converts it back to a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d3de9-d4ce-4674-b832-6b36da164b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2Doc(dtMatrix, features, index):\n",
    "    \"\"\"Turns each row of the document-term matrix into a list of terms\"\"\"\n",
    "    row = dtMatrix.getrow(index).toarray()\n",
    "    non_zero_indices = row.nonzero()[1]\n",
    "    words = [features[idx] for idx in non_zero_indices]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41e469-d996-4595-9d7d-37e799206555",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocsAsTerms = [matrix2Doc(dtm, feature_names, i) for i in range(dtm.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba40d9d-9587-479d-a496-c7057c3072ab",
   "metadata": {},
   "source": [
    "Check that we have all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e28bb-0490-475a-ac94-81fc5e4e9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allDocsAsTerms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d29b95-d2b4-49d0-8a3a-e91c849cddda",
   "metadata": {},
   "source": [
    "Add a column to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c44a4-ebf2-4bad-9008-050d4af37769",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs['terms'] = allDocsAsTerms\n",
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba34c1-e132-447c-9304-f084af84e8ff",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## 3. Fit the LDA model\n",
    "\n",
    "Now that the data is ready and we understand well how it is represented (and how sparse it is), let us fit the LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632eb57-7a22-4e3c-9a6a-8615859147ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: Initialize the model\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=15, # we are picking the number of topics arbitrarely at the moment\n",
    "                                random_state=0)\n",
    "\n",
    "# Step 2: Fit the model\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6995b3-15d9-42de-a289-f1f797a18cbc",
   "metadata": {},
   "source": [
    "The representation of topics can be accessed this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59e523-b7bd-418e-a7f6-17bd6a59f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a4970-0d1f-4272-9f85-ec7a594ad549",
   "metadata": {},
   "source": [
    "What are the dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ab118-d07e-4d26-8b26-fea7e06fea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1e132-5d4b-42b5-bce2-46797d18e222",
   "metadata": {},
   "source": [
    "So, this is a 15 by 4504 matrix, where each row is one of our topics and each column is a word (term). The values that we see are **not** probabilities, they are the **parameters** fitted by the LDA model for the topic-term distribution. We can see that they are not probabilities, since at least some of them seem to have a value > 1. \n",
    "\n",
    "These values are so-called \"pseudo-counts\" that reflect how many times, probabilistically speaking, each word was assigned to each topic across the entire corpus, adjusted by the model's learning process. The values are proportional to the probability of a term given a topic, but they need to be normalized to sum to one across each row to represent actual probabilities.\n",
    "\n",
    "Now that we have such a **topic-term distribution**, we can find the top words associated with each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87bc6dd-7180-426f-b289-ae47c3534a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([features[i]\n",
    "                        for i in topic.argsort()[:-no_top_words-1:-1]])) # syntax for reversing a list [::-1]\n",
    "\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2afd9-7baf-4603-a19d-b5f72b7de0c4",
   "metadata": {},
   "source": [
    "**To note:** Looking at these words, it is hard to decide what topic each of them represents since words about food, realestate, and science are mixed together in each topic. Topic 11 seems relatively homogenous, it's clear that it is talking about food. \n",
    "\n",
    "Knowing how sparse our document-term matrix was (only 234 documents, but 4504 terms) it is to be expected that there isn't enough data to learn a better model that captures better topics (and the words associated with them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a344c-b155-4fcf-b9e9-5c7c42e7ea3a",
   "metadata": {},
   "source": [
    "### The document-topic matrix and dominant topics\n",
    "\n",
    "In the prior step, by fitting the LDA model, we found the topics that are present in our corpus. Now, we will use these topics to generate the documents. For that, we will use the method `transform`. This method will transform our document-term matrix into a new matrix, the document-topic matrix. This is where the **dimensionality reduction** is happening. We go from the large document-term matrix to a narrow document-topic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ac43e-6658-491e-8780-55bcf4cc5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist = lda.transform(dtm)\n",
    "doc_topic_dist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5530a8-aee2-45c1-94ac-c8ab708f8f64",
   "metadata": {},
   "source": [
    "Verify the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ce858-523f-4005-8efc-63c2a3b1b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d732cc5-9f68-426f-88b7-e2fb29532747",
   "metadata": {},
   "source": [
    "**Meaning of the matrix values:** The entries in this matrix represent the proportion of the document's content that is attributed to each topic. This means each row of the output matrix is a distribution over topics for the corresponding document and should sum to one. We can easily test that by getting the sum of a row:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7240d-4f78-4d25-af41-91652de7c104",
   "metadata": {},
   "source": [
    "**Better representing the document-topic matrix**\n",
    "\n",
    "The document-topic matrix above is not very legible, we will create a dataframe that has a better representation. First, I'll modify the function `display_topics` to show a few terms for each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a1f92-6803-4591-ae61-dabdf3bdb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayHeader(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    topicNames = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topicNames.append(f\"Topic {topic_idx}: \" + (\", \".join([features[i]\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]])))\n",
    "    return topicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96371208-d821-4f08-8e13-3a148df7dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "topicnames = displayHeader(lda, feature_names, 5)\n",
    "\n",
    "# index names\n",
    "docnames = allDocs.index.tolist() # We will use the original names of the documents\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(doc_topic_dist, 3), \n",
    "                                 columns=topicnames, \n",
    "                                 index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1) # finds the maximum argument\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abe294-73e9-4649-a6b3-1a6613398753",
   "metadata": {},
   "source": [
    "Let's look at some documents between food and realestate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533f72c-1c5f-4693-ba3e-6339634bc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic[76:86]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5325654-87ca-413b-8575-2d0e017f39ea",
   "metadata": {},
   "source": [
    "One interesting thing here is that articles food_78 and food_79 seem to share the dominant topic, just like realestate_1 and realestate_2. Interestingly, realestate_5 has two topics with value > 0.1, both of which seem to be primarely about real estate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2294d8f-d75d-409f-94fc-8600890ef120",
   "metadata": {},
   "source": [
    "### Topic distribution across documents\n",
    "\n",
    "Now that we have the document-topic matrix, we can see which topics show up most frequently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b6d83-982f-4214-a09d-719ce7076fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3071b0-4bf2-4dc8-b805-ad060d93546b",
   "metadata": {},
   "source": [
    "### Challenge yourself: Add two more columns\n",
    "\n",
    "Using your pandas skills add two new columns to this dataframe:\n",
    "\n",
    "1. a column with the top 10 words of the corresponding topic. (see Topic Num for the topic number)\n",
    "2. a column that lists the document names associated with the topic (document names are things like food_1, food_2, etc.)\n",
    "\n",
    "By adding these two columns it will be a bit easier to understand what is going one with the model and whether it is capturing something about the corpus of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8067b54-8ddd-4715-a8a2-75d07369491d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee5a5e5-80c0-488c-9a0c-b2286009393e",
   "metadata": {},
   "source": [
    "### Interpretation Task\n",
    "\n",
    "Pick a topic that doesn't have many documents assigned to it and then read all the articles (see dataframe at the start of the notebook) associated with this topic. Do you see any reason for why they were given the same dominant topic? Can you summarize in a single phrase what the meaning of that topic is? (Also make use of the top 15 words for that topic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04a71b-ced1-435d-b4ba-8dc003c8675f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10a872c0-923b-4c7f-9afb-cd05455cc901",
   "metadata": {},
   "source": [
    "<a id=\"sec4\"></a>\n",
    "## 4. Grid Search: Find number of topics\n",
    "\n",
    "In the example so far, we arbitrarely chose the number of topics to be 15. However, that is not the right way to go about it. We whould use methods for selecting the optimal number of topics. This can be done through a mechanism known as GridSearch with cross-validation that builds multiple models and then compares them to see which one performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e66c50-a2da-4a3d-a6ca-90ee1ab576b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We are going to test multiple values for the number of topics\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35]}\n",
    "\n",
    "# Initialize the LDA model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Initialize a Grid Search with cross-validation instance\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "grid.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf126a6-327f-4a89-9b37-c2cf483c987c",
   "metadata": {},
   "source": [
    "Let us look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a55148-df6e-42ba-b11d-2cd2179f2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412e2f6-56d8-4b82-a667-5b934a0ea374",
   "metadata": {},
   "source": [
    "Since this representation is a bit overwhelming, let's access a few features of the grid instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a27fe7-3704-43a4-beea-69d5898d00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ede5a-61a2-40fc-95c0-1272f3e39c76",
   "metadata": {},
   "source": [
    "The results are showing that the best LDA model should have 5 topics, the smallest number we tried. This raises the question of whether we should try other small numbers, which I'm doing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ff1e3-c05c-48eb-85c8-2c55979d00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'n_components': [1,2,3,4,5,6]}\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "grid.fit(dtm)\n",
    "\n",
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43140116-4981-40ae-a3f5-b3a3968fc7a1",
   "metadata": {},
   "source": [
    "This result shows that actually the best number of topics for this corpus is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad0057-13ff-4bd1-8697-f4d94c24be0e",
   "metadata": {},
   "source": [
    "**Meaning of Log Likelihood**. \n",
    "\n",
    "Log Likelihood is the logarithm of the probability of observing the given data under the model with specific parameters. Essentially, it measures how well the model explains the observed data. (It is a conditional probability.)\n",
    "\n",
    "**Meaning of perplexity**\n",
    "\n",
    "Perplexity is a common metric used to evaluate the quality of probabilistic models. It reflects how well the model describes or predicts the documents in the dataset.\n",
    "\n",
    "A lower perplexity score suggests that the model is more certain about its predictions (i.e., the probability distributions it assigns to unseen documents are more accurate). This means that the topic distributions learned by the model are a good fit for the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d0ca2-e901-498b-9555-36906db69ffe",
   "metadata": {},
   "source": [
    "**Words for best modesl with one topic**\n",
    "\n",
    "Let's see what are the top words for the best model with one topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b987c2-8a89-4576-b876-ef434a14c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(best_lda_model, feature_names, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20193f66-1255-49c4-acda-146fc9407c4e",
   "metadata": {},
   "source": [
    "As we can see it is a mix of food and realestae and New York. If we had documents with more distinct nature and more of them we might have seen something else. \n",
    "\n",
    "However, the point of this tutorial was to show the mechanics of building LDA models. \n",
    "\n",
    "Now it's time to take what you saw here and apply it to your projects.\n",
    "\n",
    "Have fun exploring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a94654-fe6b-43d6-b1a2-873e589e9e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
